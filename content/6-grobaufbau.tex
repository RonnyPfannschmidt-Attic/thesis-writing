\chapter{Analyse und Design}
\label{chap:design}

Im vorhergehenden Kapitel wurden Ziele und Leistungskriterien
für das \ac{CI}-System festgelegt.
Diese werden nun auf konzeptueller Ebene umgesetzt werden.
Dazu wird zuerst ein Überblick des Gesamtkonzeptes in der Systemarchitektur und den Schemata gegeben.
Anschließend wird die Logik einzelner Systemkomponenten genauer betrachtet.
Schließlich werden besondere Ansätze zur Interaktion mit der Datenbank betrachtet.
Abschließend wird die Mechanik der Durchführung von Arbeitsschritten sowie die Erweiterungen noch einmal näher betrachtet.

%XXX: continue


\section{Systemarchitektur}
\label{sec:design:sysarch}
Dieser Abschnitt gibt Aufschluss über die Grobstruktur des \ac{CI}-Systems auf logischer und physischer Ebene.

\subsection{logische Ebene}

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth]{imageinput/grob-layout-komponenten-logisch.png}
  \caption{\"Ubersicht über Systemkomponenten - logisch}
  \label{fig:grob-layout-komponenten-logisch}
\end{figure}


Die erste wichtige Komponente ist der Eingang.
In ihm gehen Aufträge aus verschiedensten Quellen ein.
Nachdem sie validiert wurden, werden die Aufträge an
die zweite wichtige Komponente, den Manager, weitergegeben.
Dort werden sie vorbereitet und entsprechend der Build-Matrix Arbeitspakete erstellt.
Nun treten Manager und Arbeiter in eine Interaktion,
um zu bestimmen, welcher Arbeiter welche Arbeitspakete bearbeitet.
Anschließend werden die Arbeitspakete von den jeweilig designierten Arbeitern abgefertigt (siehe \cref{fig:grob-layout-komponenten-logisch}).

%XXX: more


\subsection{physische Ebene}

\begin{figure}[ht] 
  \centering
  \includegraphics[width=\textwidth]{imageinput/grob-layout-komponenten.png}
  \caption{Übersicht über Systemkomponenten - physisch}
  \label{fig:grob-layout-komponenten}
\end{figure}

Der physische Aufbau unterscheidet sich stark von den bisher da gewesenen CI-Systemen.
Ein Grund dafür ist der Fokus auf die verteilte Datenbank.
Anstatt direkter Kommunikation,
wird die Interaktion mit der verteilten Datenbank den Programmablauf der einzelnen Komponenten bestimmen.

Das System besteht somit aus Komponenten, welche alle als Clients einer verteilten Datenbank operieren.
Die \Cref{fig:grob-layout-komponenten} zeigt die Struktur.
Nennenswert ist dabei die Bindung einer Komponente an bestimmte Knotenpunkte der Datenbank. Dies dient der Kontrolle der Lokalität und wird später noch vorgestellte Verfahrensweisen unterstützen.

%XXX more

\section{Datenschema}
\label{sec:design:schema}

\begin{figure}[ht] 
  \centering
  \includegraphics[width=\textwidth]{imageinput/datenstrukturen-step-templates.png}
  \caption{Grundlegende Datenstrukturen}
  \label{fig:datenstrukturen}
\end{figure}

Das grundlegende Datenschema, in \Cref{fig:datenstrukturen} als \ac{UML}-Klassendiagramm dargestellt,
beschreibt die Daten des Kernsystems und einige ihrer Interaktionen.

Die wichtigsten Datentypen sind dabei Projekt, Auftrag (Order),
Arbeitspaket (Task) und Arbeitsschritt (Step).

\subsubsection{Projekt}

Das Projekt beinhaltet neben dem Namen auch alle Informationen,
die später für das Erstellen von Arbeitspaketen sowie
die Ausführung einer Integration benötigt werden.
Dazu gehört das Quellcode-repository (``repo''), von dem später
die Quelltexte für das dem Test unterworfenen Projekt bezogen werden.
Weiterhin beinhaltet es die Build-Achsen,
welche die Wertebereiche der einzelnen Ebenen der Build-Matrix
beschreiben.

\subsubsection{Arbeitsschritt Templates}

Der mitunter wichtigste Teil eines Projektes ist jedoch die Beschreibung der Arbeitsschritte als Templates.
Die Darstellung als Template ist dabei bewusst gewählt,
sie ermöglicht es jedem Arbeitspaket speziell konfigurierte Arbeitsschritte zur Verfügung zu stellen.
Außerdem bewirkt die erneute Speicherung in der Datenbank,
dass das Bearbeiten der Schritte eines Projektes keinen Einfluss auf bereits erstellte Arbeitspakete hat.
Zudem stellen die extra Objekte auch einen Anschlusspunkt für die Datensammlung dar.
Die Methode \textit{construct} des Templates dient dazu,
einen Arbeitsschritt, angereichert mit einer entsprechenden Konfiguration, zurückzugeben.

\subsubsection{Auftrag}

Ein Auftrag beinhaltet grundsätzlich eine Referenz auf das zugehörige Projekt,
außerdem beinhaltet er Überschreibungen und/oder Zusätze für die Build-Achsen.
Dies ermöglicht es sowohl in den Achsen eingeschränkte
als auch erweiterte Aufträge zu erstellen.
Diese werden später genauer erklärt.
Zusätzlich beinhaltet der Auftrag einen Status, dieser beinhaltet den aktuellen Stand der Bearbeitung.

\subsubsection{Arbeitspaket}
%XXX: eventuell projekt hier nicht referenzieren
Ein Arbeitspaket beinhaltet, neben Referenzen zu dem Projekt und dem Auftrag,
seine Spezifikation. Diese gibt die Ausbildung aller Build-Achsen für dieses Paket an.
Des Weiteren beinhaltet es den Index, dieser gibt die numerische Position in der Build-Matrix an.
Auch ein Arbeitspaket hat einen Status, welcher den aktuellen Bearbeitungsstand zum Ausdruck bringt.
Zudem bestimmt das Feld ``Owner'' den Arbeiter, welcher Arbeiter das Arbeitspaket letztendlich bearbeiten wird.

\subsubsection{Arbeitsschritt}

Ein Arbeitsschritt referenziert das zugehörige Arbeitspaket.
Neben den Zeitpunkten für Anfang und Ende seiner Ausführung,
benennt er im Feld ``stepper'', um welche Art von Arbeitsschritt es sich handelt.
Das Feld ``status'' gibt Auskunft über den aktuellen Stand der Bearbeitung.
Das Feld ``data'' soll weitere dynamische Informationen zum Ausdruck bringen,
die bei der Ausführung genutzt werden.

%XXX: dies dient \ldots


\subsubsection{Event}
%XXX referenz auf task?

Ein Event bringt Datensammlung zur Laufzeit zum Ausdruck.
Neben den Referenzen für den Arbeitsschritt und das Arbeitspaket,
beinhaltet es eine Indexnummer und einen Timestamp.
Die Indexnummer ist eine aufsteigende Zahl
und gibt den Events eines bestimmten Arbeitsschritts eine feste, eindeutige Reihenfolge.
Der Timestamp gibt den Events eine zeitliche Ordnung (welche jedoch nicht eindeutig ist).


Zusätzlich zu diesen Basisdaten beinhaltet ein Event beliebige weitere optionale Felder.
Einige mögliche (und ihre Datentypen) sind:

\begin{itemize}
    \dhitem[returncode: Number] Rückgabe-wert eines Prozesses bei seiner Beendigung.
    \dhitem[line: Text] Textzeile eines Datenstromes der Ausgabe
    \dhitem[lineno: Number] Zugehörige Zeilennummer
    \dhitem[stream: Name] Zugehörige Name des Datenstromes
    \dhitem[start: Name] Mitteilung über den Start eines bestimmten Vorganges
    \dhitem[end: Name] Mitteilung über den Abschluss eines bestimmten Vorganges
\end{itemize}




\section{Logik der Komponenten}
\label{sec:design:logik}

Dieser Abschnitt behandelt die grundlegende Logik  der Einzelteile des Systems,
sie bilden die Bausteine für das Gesamtsystem.

%XXX MORE

\subsection{Auftragsannahme}

Die Auftragsannahme lässt sich grob in zwei Abschnitte einteilen.
Zuerst geht ein Auftrag ein.
Dies kann je nach Methode mehrere Schritte umfassen.
Danach wird der Auftrag überprüft und damit angenommen oder abgelehnt.


\begin{figure}[ht]
  \centering
  \includegraphics[height=5in]{imageinput/lebenszyklus-auftrag-eingang.png}
  \caption{Auftragsannahme: Flussdiagramm}
  \label{fig:lebenszyklus-auftrag-eingang}
\end{figure}

In \cref{fig:lebenszyklus-auftrag-eingang} ist das Flussdiagramm zur Auftragsannahme dargestellt.
\FloatBarrier

\subsubsection{Eingang}

Der Auftragseingang gestaltet sich in der Praxis vielseitig.
Da nicht alle Quellen sofort einen vollständigen Auftrag generieren können,
beginnt ein Auftrag im Zustand eingehend.
Anschließend werden weitere Daten für diesen Auftrag gesammelt.
Sind schließlich alle Daten zusammengekommen,
so wird der Eingang festgehalten und der Auftrag wird vom System weiterverarbeitet.

%XXX Quellen betrachten``
Betrachtet werden die Anforderungen für die Quellen
\begin{description}
    \item[E-Mail]
        Der Eingang per E-Mail kann in zwei Formen erfolgen:
        Zum einen kann der gesamte Auftrag in einer einzigen E-Mail enthalten sein.
        Zum anderen kann sich der Auftrag über mehr als eine E-Mail erstrecken.
        Beispiel hierfür sind z.B. Mercurial Patchbombs \cite{mercurial:patchbomb}.
        Ist ein Auftrag fertiggestellt, so ist eine Antwort-E-Mail hilfreich.
        Wichtig ist, dass E-Mails Unbekannter auf keinen Fall
        akzeptiert werden sollten.
    \item[Mailingliste]
        Der Eingang per Mailingliste ist dem Eingang per E-Mail sehr ähnlich.
        Haupt-unterschied ist, dass anstelle einer privaten Korrespondenz
        ein öffentliches Forum genutzt wird. Dabei sollen auch E-Mails Unbekannter 
        bearbeitet werden können.
        Ein bekanntes Beispiel für eine Mailingliste mit Patches
        ist die Mercurial Mailingliste \cite{mercurial:mailingliste}.
    \item[Web Formular]
        Web-Formulare bieten eine intuitive Möglichkeit,
        einen Auftrag zu bearbeiten und vorzubereiten,
        bevor man ihn letztendlich in Bearbeitung gibt.
    \item[HTTP Hook]
        HTTP Hooks sind ein traditionelles Werkzeug,
        um \ac{CI}-Systemen Änderungen mitzuteilen.
        Da sie lediglich die Reaktion auf einen HTTP Request sind,
        sind sie einfach in externe Werkzeuge, wie z.B. \ac{SCM} integrierbar,
        und dienen dazu, Aufträge für die Standardkonfiguration
        eines Projektes abzusetzen, wenn externe Ereignisse,
        wie z.B. ein SCM commit, eintreten.
    \item[Zeitsteuerung]
        DIe Zeitsteuerung ist ein weiteres traditionelles Werkzeug,
        um Aufträge in Standardkonfiguration abzusetzen.
        Zu festgesetzten Zeitpunkten, wie zb. Nachts oder nach
        Arbeitsschluss, werden Aufträge abgesetzt.
    \item[HTTP API]
        Eine HTTP API kann als Basis sowohl für Testwerkzeuge
        als auch für Web-Formulare dienen.
        Sie ermöglicht Programmen das Absetzen von Aufträgen.
\end{description}

Für den Prototypen ist zumindest die HTTP API notwendig,
um dem System zu Demonstrationszwecken Aufträge zu erteilen.


\subsubsection{Validation}

%XXX: genauer beschreiben

Die Validation verfolgt das Ziel, Aufträge auch aus weniger vertrauenswürdigen Quellen anzunehmen.
Dies ermöglicht Verwendung ähnlich zu TravisCI, was es erlaubt, Zuarbeiten von Außenstehenden zu testen.
Für die Überprüfung stehen verschiedene Möglichkeiten zur Verfügung.
Ein Eingang per Mail/Mailingliste oder Pull-Request auf einer Code-Hosting-Site,
kann z.B. nach erstmaliger Erlaubnis, wiederholt zugelassen werden,
während Informationen die Mitarbeiter einsenden z.B. an ihr Arbeitsverhältnis gebunden werden können.

Zeitgesteuerte Eingänge innerhalb des Systems können jedoch grundsätzlich zugelassen werden.

Den Abschluss der Validation stellt die Markierung des Auftrages als ``valide'' oder ``invalide'' dar.

\subsection{Management}

\begin{figure}[ht] 
  \centering
  \includegraphics[height=4in]{imageinput/lebenszyklus-auftrag-abarbeitung.png}
  \caption{Auftragsannahme: Flussdiagramm}
  \label{fig:lebenszyklus-auftrag-abarbeitung}
\end{figure}

In \cref{fig:lebenszyklus-auftrag-abarbeitung} wird die Vorbereitung, die Abarbeitung und der Abschluss eines Auftrags illustriert.


\subsubsection{Auftragsvorbereitung}

In der Auftragsvorbereitung werden Details aus dem Projekt zum Auftrag hinzugefügt.
Die vordefinierten Build-Achsen werden vom Projekt übertragen.
Dies stellt sicher, dass der Auftrag und sein Umfang eindeutig bestimmt sind,
bevor mit der Erstellung von Arbeitspaketen begonnen wird.


\subsubsection{Bereitstellung von Arbeitspaketen}

Das Bereitstellen von Arbeitspaketen stellt den Anfang der eigentlichen Arbeitsphase dar.
Entsprechend der Werte der Build-Achsen des Auftrages, werden nun die Arbeits\-pakete generiert,
wobei jedes Arbeitspaket eine der Wertekombinationen darstellt.
Nachdem alle Arbeitspakete erstellt sind, ist die Bearbeitung des Auftrages an sich abgeschlossen. Der Rest der Bearbeitung befasst sich nur mit den Arbeitspaketen.

\subsubsection{Abschluss von Aufträgen}

Der Abschluss eines Auftrages ist ein Ereignis, welches impliziert werden kann.
Im zu entwickelnden System wird der Abschluss eines Auftrages definiert
als der Zustand, welcher eintritt, wenn alle Arbeitspakete eines Auftrages
einen finalen Zustand erreichen.

Dies vereinfacht die Behandlung des Auftragsabschlusses,
da man nach Abschluss von Arbeitspaketen keine weitere Operationen durchführen muss,
um den eventuellen Abschluss des Auftrages festzustellen.

\subsection{Zuteilung/Abarbeitung von Arbeitspaketen}

\cref{fig:lebenszyklus-arbeitspaket} Stellt den Lebenszyklus eines Arbeitspaketes als Zustandsgraph dar.
Jedes Arbeitspacket beginnt dabei im Zustand \verb|new|.

\begin{figure}[ht] 
  \centering
  \includegraphics[height=4.5in]{imageinput/lebenszyklus-arbeitspaket.png}
  \caption{Lebenszyklus eines Arbeitspaketes bei Ausschreibungen}
  \label{fig:lebenszyklus-arbeitspaket}
\end{figure}


\subsubsection{Vorbereitung Abarbeitung}

Bevor ein Arbeitspaket bereit (\verb|ready|) für die Zuteilung ist,
müssen seine Arbeitsschritte erstellt werden.
Dazu wird die Ausprägung der Build-Achsen für dieses Arbeitspaket hergenommen.
Auf ihrer Basis werden die Variablen in den Schritt-Templates des Projektes
ausgefüllt und die Arbeitspakete für das Arbeitspaket erstellt. 

\subsubsection{Zuteilung}

Die Zuteilung von Arbeitspaketen ist ein komplexes Thema.
Sie wird daher anschließend in \cref{sec:methoden:zuteilung} behandelt.
Ihr Ziel ist es, dass ein Arbeitspaket einem Arbeiter zugeteilt wird.

\subsubsection{Abarbeitung von Arbeitspaketen}

Bei der Abarbeitung von Arbeitspaketen geht es darum,
die einzelnen Arbeitsschritte des Arbeitspaketes nacheinander linear abzuarbeiten.
Tritt ein Fehler auf oder wird ein Wunsch zum Abbruch im System eingetragen,
so kann der Prozess vorzeitig beendet werden. Details hierzu werden in \cref{sec:schritt-kontext}.

\subsubsection{Abschluss Abarbeitung}

Ist die Bearbeitung der einzelnen Schritte eines Arbeitspaketes abgeschlossen,
so muss das Resultat zusammengefasst werden. 
Dabei wird die Entscheidung getroffen,
ob ein Arbeitspaket zum Erfolg oder Misserfolg geführt hat.

\subsection{Überblick Methoden der Zuteilung von Arbeitspaketen}
\label{sec:methoden:zuteilung}

Dieser Abschnitt beschäftigt sich mit der Zuteilung von Arbeitspaketen.
Grundsätzlich gibt es zwei Möglichkeiten dies zu bewerkstelligen.
Es muss festgestellt werden, welche Methode besser geeignet ist.

\subsubsection{Melde-Verfahren}
% MOAR
Beim Melde-Verfahren teilt der Arbeiter nur seinen Wunsch, ein noch nicht näher festgelegtes Arbeitspaket zu bearbeiten, mit.
Anschließend wartet er darauf, dass dieser erfüllt wird.
Dabei liegt die Logik der Zuteilung komplett beim Manager,
er muss also über das Wissen verfügen,
welcher Arbeiter in der Lage ist, welche Arbeitspakete zu bearbeiten.

\begin{figure}[ht] 
    \centering
  \begin{sequencediagram}
      \newinst{worker}{:Worker}
      \newinst[1]{manager}{:Manager}
      \mess{worker}{token <spec>}{manager}
      \mess{manager}{work <spec>}{worker}
      \mess{worker}{result}{manager}
  \end{sequencediagram}
  \caption{Auftragszuteilung: tokenbasiert}
  \label{fig:auftrag-zuteilung-token}
\end{figure}

Die \cref{fig:auftrag-zuteilung-token} stellt den Prozess noch einmal graphisch dar.
Vorteil des Verfahrens ist, dass die Zuteilung ein eindeutiger Prozess ist.
Jedoch benötigt der Manager genaues Wissen über die Arbeiter,
um seiner Aufgabe gerecht zu werden.

\subsubsection{Ausschreibungsverfahren}

Beim Ausschreibungsverfahren teilt der Manager die offenen Arbeitspakete mit.
Anschließend können Arbeiter einen Anspruch auf diese anmelden.
Sie treten dabei, wie in \cref{fig:auftrag-zuteilung-claim} gezeigt, in Konkurrenz.
Der Manager entscheidet dann, welcher Arbeiter welches Arbeitspaket bearbeiten darf.
%MOAR

Dies erlaubt Arbeitern wesentlich autonomer zu agieren.
Sie sind nun in der Lage, frei zu entscheiden,
welche der verfügbaren Aufträge sie bearbeiten wollen.
Der Manager ist auch vereinfacht,
da er nur noch die Entscheidung für den Zuschlag treffen muss.
Es ist nicht notwendig, spezielles Wissen über die Arbeiter und ihre Fähigkeiten zu haben. 


\begin{figure}[ht]
  \centering
  \begin{sequencediagram}
      \newinst{workera}{:Worker A}
      \newinst[1]{manager}{:Manager}
      \newinst[1]{workerb}{:Worker B}
      \mess[1]{manager}{availiable}{workera}
      \prelevel
      \prelevel
      \mess[1]{manager}{availiable}{workerb}

      \mess[1]{workera}{claim}{manager}
      \prelevel
      \prelevel
      \mess[2]{workerb}{claim}{manager}
      %XXX: better call?
      %\prelevel
      %\prelevel
      %\begin{call}{manager}{approve}{manager}{workera}
      %\end{call}
      \mess{manager}{approve A}{workera}
      \prelevel
      \mess{manager}{approve A}{workerb}
  \end{sequencediagram}
  \caption{Auftragszuteilung: Ausschreibungsbasiert}
  \label{fig:auftrag-zuteilung-claim}
\end{figure}

\subsubsection{Auswahl}

Das Ausschreibungsverfahren zeigt sich im Vergleich zum Meldeverfahren
wesentlich flexibler.
Die Möglichkeit, Detailkenntnisse über die Fähigkeiten eines Arbeiter 
beim Arbeiter zu belassen, sorgt dafür, dass Arbeiter wesentlich autonomer sind.
Dies hat zur Folge, dass der Algorithmus für die Zuteilung von Arbeitspaketen wesentlich vereinfacht wird,
da es für ihn nun unerheblich ist, wer den Zuschlag bekommt.
Das Endresultat wird durch die Zuteilung nicht beeinflusst.


\section{Besondere Ansätze zur Datenbank-Interaktion}
\label{sec:design:bes-ansaetze}

Dieser Abschnitt behandelt einige Ansätze zum Zugriff auf die Daten in der verteilten Datenbank.
Sie unterstützen die Konsistenz der Daten.

%XXX: http://dbmsmusings.blogspot.de/2010/04/problems-with-cap-and-yahoos-little.html


\subsection{CAP Abdeckung}

Wie bereits in \Cref{sec:base:cap} erwähnt,
ist es immer nur möglich zwei der drei Aspekte des CAP-Theorems abzudecken.

Jedoch ist es durchaus legitim für verschiedene Teile
einer verteilten Applikation unterschiedliche Bereiche abzudecken.
Sobald genau definiert ist, für welche Daten in welchem Kontext welche Eigenschaften benötigt werden,
kann ein konsistentes Modell geschaffen werden.

Wichtig ist bei dieser Betrachtung, dass die unterschiedlichen Komponenten des entwickelten CI-Systems
nicht zwingend eine direkte Konsistenz-Bindung untereinander benötigen.
Wichtig ist nur die Konsistenz zwischen einer Komponente
und dem Datenbankknoten, mit dem sie kommuniziert.

Das Hauptsystem, in dem alle Komponenten in Kommunikation stehen,
%XXX: s1?
soll nach Systemanforderung \textbf{S1} immer verfügbar sein und somit einen Teil-Ausfall  verkraften.
Somit kommt für die Kommunikation zwischen Komponenten nur das Modell \textbf{A-P} in Frage
(was verfügbar und partitionstolerant bedeutet).

Die Anbindung einzelner Komponenten an ihre Knoten in der Datenbank hat jedoch andere Anforderungen.
Da eine direkte Anbindung an die Datenbank für das Funktionieren einer Komponente unabdingbar ist,
kann in diesem Fall nur das Modell \textbf{C-A} zum Einsatz kommen.
(was konsistent und verfügbar bedeutet)

%XXX: http://www.infoq.com/articles/cap-twelve-years-later-how-the-rules-have-changed


\subsection{Status-Maschinen zur Wahrung der Konsistenz}

%XXX: Literatur
% http://blog.incubaid.com/2012/10/25/caulking-your-distributed-algorithm-implementation/
\nocite{statechart}

Zustands-Maschinen sind ein allgemein bekanntes Werkzeug,
um den Ablauf eines komplexen Programms zu beschreiben oder zu erklären.
In der Regel wird dazu ein sog. ZustandsGraph verwendet.
Dieser ist ein gerichteter Graph, der die Zustände und Zustandsänderungen eines Systems beschreibt.

Wie bereits in \Cref{fig:lebenszyklus-arbeitspaket} gezeigt,
stellt der Lebenszyklus eines Arbeitspaketes einen solchen Zustandsgraph dar.
Als Besonderheit ist er sogar frei von Zyklen.
Dadurch ist es unmöglich, den gleichen Zustand noch einmal zu erreichen.

Bindet man zusätzlich noch die Zustandsänderungen an bearbeitende Komponenten,
so ist auch bei einer Partitionierung der Datenbank die Konsistenz der Gesamtsystems gewährleistet.
%XXX: moar?


Mit dem Eingang und der Abarbeitung von Aufträgen verhält es sich ähnlich,
jedoch ist der Graph dort wesentlich einfacher.
Die \Cref{fig:lebenszyklus-auftrag-eingang,fig:lebenszyklus-auftrag-abarbeitung} zeigen den groben Ablauf.
Der Übergang zwischen Eingang und Abarbeitung ist die der Validation angeschlossene Markierung zur Bereitschaft.
Da es nur diesen einen Punkt des Austausches gibt, ist die Wahrung der Konsistenz des Auftrages denkbar einfach.
Mit der Bereitschaft wird die Verantwortung vom Eingang zur Abarbeitung übertragen.

\subsection{Abbildung des verteilten Systems auf Datenbanken}

Die Abbildung eines verteilten Systems auf eine Datenbank
hat einige überaus erfreuliche Nebeneffekte.

Im Client-Server-System müssen der Client und Server extra Nachrichten austauschen, um das gleiche Bild der Welt zu bekommen, wobei jedes System eine eigene Version des Zustandes hat.
Beim Datenbank-basierten System ist der Status jedoch in der Datenbank und
die einzelnen Komponenten des Systems müssen somit nicht weiter eigene Kopien vorhalten.

Eine Änderung des Status wird nun durch eine Änderung in der Datenbank zum Ausdruck gebracht.
Sobald die Änderung in die Datenbank eingebracht ist,
ist der Vorgang des Übermittelns für die sendende Komponente abgeschlossen.
Sie muss nicht wie bisher auf eine Rückantwort warten.


\section{Arbeitsschritte und der Kontext ihrer Ausführung}
\label{sec:schritt-kontext}

%XXX

\subsection{Überblick und grundlegender Ablauf}

\begin{figure}[!ht]
    \centering
    \includegraphics[height=0.8\textheight]{imageinput/klassen-arten-arbeitsschritt.png}
    \caption{Arten und Ablauf von Arbeitsschritten}
    \label{fig:klassen-arten-arbeitsschritt}
\end{figure}

Wie man an der \Cref{fig:klassen-arten-arbeitsschritt} gut erkennen kann,
bildet das Arbeitsverzeichniss (ProcDir) die Basis
für die Durchführung der Arbeitsschritte eines Auftrages.

Es bindet alle Operationen, die notwendig sind,
um die Kontrolldaten (Steps, siehe \Cref{fig:datenstrukturen})
aus der Datenbank zu laden und diese dann an ausführende Objekte zu binden (Proc).

Der Lebenszyklus eines ``Proc'' Objektes wird dabei vom zugehörigen ProcDir verwaltet
und das Proc Objekt sollte nur innerhalb der Methode ``run'' existieren.

%XXX: More

\subsection{Lebenszyklus einzelner Arbeitsschritte}


\begin{figure}[ht] 
    \centering
    \includegraphics[height=3.4in]{imageinput/lebenszyklus-arbeitsschritt.png}
    \caption{Zustandsdiagramm eines Arbeitsschrittes}
    \label{fig:lebenszyklus-arbeitsschritt}
\end{figure}

Der Lebenszyklus eines einzelnen Arbeitsschrittes beginnt mit der Speicherung der Arbeitsschritte für ein Arbeitspaket. Ein Arbeitsschritt wird sich, bis er zur Ausführung kommt, im Zustand \verb|new| befinden.

Kommt es schließlich zur Ausführung, so wechselt der Zustand nach \verb|building|.
Und nach der Ausführung wird festgestellt, ob der Ablauf erfolgreich war und der Zustand entsprechend auf \verb|completed| oder \verb|failed| gesetzt.

Solange ein Arbeitsschritt in Bearbeitung ist, kann sein Abbruch
durch den Zustand \verb|canceling| beantragt werden.
Ein Abbruch zwingt den Arbeitsschritt in den Zustand \verb|canceled|.
Wird er jedoch vor Bearbeitung des Abbruchs abgeschlossen,
so findet ein normaler Abschluss statt.

\subsection{Datensammlung zur Laufzeit}

Datensammlung zur Laufzeit dient dazu, zeitnah den Zustand eines Integrationsprozesses zu bewerten.
Üblicherweise werden dabei die Standardausgabe und Standardfehlerausgabe berücksichtigt. Aber auch statistische Informationen und einzelne Testresultate sind hilfreich. Im System wird dazu der \verb|Event| Datentyp verwendet.

\subsection{Datensammlung nach Abschluss eines Schrittes}

Datensammlung nach dem Abschluss eines Arbeitsschritts
umfasst in der Regel verschiedenste Dateiformate.
Diese werden aus den verschiedensten Gründen generiert.
Üblich sind Test-Resultate, Logdateien, Build-Resultate und Archive.

Die Abbildung dieser Datensammlung kann dabei auf 2 Arten geschehen:

\begin{enumerate}
    \item als Teil des Schrittes und
    \item als eigene Art von Schritt.
\end{enumerate}

Die Abbildung als eigene Art von Arbeitsschritt hat einige Vorteile,
da sie die Zuständigkeit vom reinen Arbeitsschritt und dem Daten-sammeln sauber trennt.

Dies macht die Werkzeuge zur Datensammlung wesentlich einfacher.
Anstatt sie in jeden Schritt integrieren zu müssen,
können sie einfach nach dem Schritt angewendet werden.

\subsection{Prozess-Schritte}

Die Aufgabe eines Prozess-Schrittes ist es,
ein Programm mit vorgegebenen Parametern auszuführen.
Dies ist der Grund, warum der ``SubprocessProc''-Datentyp einen
Prozess-Handle enthält.

Dabei fallen zur Laufzeit Daten wie z.B. Text auf den Standard Eingabe-/Ausgabe-Datenströmen an.
Außerdem verändern sich statistische Informationen über den Prozess wie Speicher-Verbrauch, I/O-Last und andere.


\subsection{Skript-Schritte}

Skript-Schritte unterscheiden sich von Prozess-Schritten in der Hinsicht,
dass sie kein Programm an sich, sondern ein Skript ausführen.
Daher können sie in die Lage versetzt werden,
weitere Laufzeit-Daten zur Verfügung zu stellen


\subsection{Quellcode Management Schritte}

Quellcode Management Schritte behandeln die Interaktion mit dem SCM.
Es wird, wenn notwendig, ein Arbeitsverzeichnis erstellt.
Danach gibt es mehrere grundlegende Operationen, die durchgeführt werden können.

\begin{description}
    \item[Eingang von Historie]
        Der Eingang von Historie bringt die lokale Historie auf den aktuellen Stand. Dies wird in verteilten \ac{SCM} ``pull'' genannt.
    \item[Aktualisierung des Arbeitsverzeichnis]
        Die Aktualisierung des Arbeitsverzeichnises bringt die Dateien im Arbeitsverzeichnis auf eine gewünschte Version.
    \item[Anwendung von Patches]
        Die Anwendung von Patches wendet Patches auf das aktuelle Arbeitsverzeichnis an.
\end{description}


\subsection{Datensammlungs-Schritte}

Datensammlungs-Schritte haben die Aufgabe
bei vorhergehenden Schritten entstandene Dateien 
in die Datenbank zu überführen.
Die Grundfunktion pflegt dabei nur den Inhalt der Datei ein.
Laufzeit-Daten dieses Schritts sind die gefundenen Dateien.

Dabei wird das Regexmuster ``pattern'' verwendet, um festzustellen,
ob eine Datei im Arbeitsverzeichniss zur Menge der gewünschten Dateien gehört.

Erweiterte Versionen dieser Schrittart könnten zusätzliche Funktionen,
wie z.B. Einpflegen von Testergebnissen aus JunitXML-Dateien, in die Datenbank,
übernehmen.


\section{Erweiterungen}
\label{sec:design:erweiterungen}

Dieser Abschnitt beschäftigt sich mit dem Aufbau der zwei Beispielerweiterungen.

\subsection{Analyse Test-Resultate}

Bei der Analyse von Test-Resultaten ist das Ziel,
Veränderungen in verschiedenen Umgebungen feststellen zu können.
Betrachtungsgrundlage sind dabei vorwiegend Unterschiede zwischen verschiedenen Arbeitspaketen und Aufträgen sowie Unterschiede zwischen zeitlich aufeinander folgenden Aufträgen oder Arbeitspaketen, welche verschiedene Plattformen, Entwickler-Zweige oder Konfigurationen betrachten, geben Aufschluss über Entwicklung und Zustand des Projektes.

Da ein großer Teil dieser Erweiterung zur Benutzeroberfläche gehört,
werden hier nur die unterstützenden Algorithmen und Datenstrukturen betrachtet.
Um überhaupt Vergleiche anstellen zu können, muss zuerst die Vergleichs-Menge bestimmt werden. Dabei erscheint die Menge an Test-Resultaten je Arbeitsschritt am geeignetsten. Im Gegensatz zur Menge an Testresultaten je Auftrag,
ist in diesem Fall für jede Konfiguration ein Set an Resultaten verfügbar.

Um Testresultate abzulegen, erscheint es sinnvoll eine weitere Art an Datenstruktur einzuführen.
Diese sollte wie die bereits definierten ``Events'' aufgebaut sein.
Jedoch soll es möglich sein, diese aus einem Prozess der den Testvorgang verwaltet,
anzulegen. Zudem sollen sie an das Arbeitspaket und nicht an den Arbeitsschritt gebunden sein.

Für die Vergleiche ist es nun notwendig,
Unterschiede zwischen zwei oder mehr Mengen an Testresultaten zu bestimmen.
Eine recht einfache Methode ist dabei die Mengen-Differenz.
Nimmt man für die Resultate von Tests eine Werte-Menge mit der Struktur $\{ Testname \rightarrow Resultat \}$ als Basis,
so ist es leicht, einen passenden Überblick aufzubauen.

Die Datenstruktur der Resultate für Vergleiche zwischen N Resultatmengen
ist dabei eine Zuordnung von
$\{ Testname \rightarrow ( Resultat_{1},\ldots,Resultat_{N})\}$
Wobei i.d.R. nur die Elemente interessant sind,
deren Resultatmenge Unterschiede und/oder Fehlschläge aufweist.
Ein gutes Beispiel für die Darstellung eines solchen Resultates
stellt der Überblick der Testresultate des ``PYPY''-Projektes \cite{pypy:overview} dar.

Die Art und Weise, wie die Mengen an Testresultaten für die Vergleiche ausgewählt werden sollen, werden in dieser Arbeit nicht betrachtet,
da dies vorwiegend ein Problem der Benutzeroberfläche ist.

\subsection{Analyse Verhalten eines Programms}

Bei der Erweiterung zur Analyse des Verhaltens eines Programms
geht es darum, das Verhalten eines Programms
in verschiedenen Konfigurationen zu testen.
Als Programm wurde dabei ein Skript gewählt,
welches einen genetischen Algorithmus umsetzt.

Im willkürlich gewählten Beispiel ist dies ein Programm,
welches versuchen soll, eine Funktion anzunähern \cite{gen:prog}.

Die Analyse soll dazu dienen, Parameter-Werte festzustellen,
die zum Erfolg des Algorithmus führen.
Bei der Betrachtung steht die Analyse der Resultate nach der Durchführung des Programms im Vordergrund.

Dabei wurden die folgenden Konfigurations-Achsen für Parameter gewählt:

\begin{description}
    \item[generations:] Menge der Generationen
    \item[population:] Größe der Population
    \item[height-weight:] Bewertungsgewicht für die Höhe des Baumes welcher die angenäherte Funktion zum Ausdruck bringt
\end{description}

Die Achsen ``generations'' und ``population'' sind dabei ein exponentiell wachsender Wertebereich zwischen 20 und 5000.
Die Achse ``height-weight'' hingegen wurde im Bereich zwischen -2 und 2 gewählt,
wobei viele Werte im Bereich $ 0<abs(x)<1$ liegen.

Die Wahl der Achsen und ihrer Parameter ist willkürlich als Teil eines ersten Tests entstanden.
Weitere Parameter und Achsenkonfigurationen sind denkbar.
Das Analysewerkzeug soll zeigen, welchen Einfluss die Parameter haben.

Um dies zu zeigen, ist es notwendig die Resultate
eines konfigurierten Durchlaufes (Auftrag) zusammenzufassen.
Die Resultate jedes einzelnen Auftrages sind dabei aus der Standardausgabe
des Programms zu entnehmen.

Für jedes Arbeitspaket eines Auftrages sind also Parameter-Werte und Ergebnis zusammenzufassen.
Anschließend können die Daten in Graphen dargestellt werden.


\section{Benutzeroberfläche}
\label{sec:design:ui}

Da die Benutzeroberfläche für den Prototypen nicht zwingend notwendig ist,
wird darauf verzichtet, mehr als nur simple Werkzeuge zur Verfügung zu stellen.
Wichtig ist dabei, dass vorgefertigte Testdaten in die Datenbank eingegeben werden können.


\section{Zusammenfassung}
\label{sec:design:zusammenfassung}

In diesem Kapitel wurden sowohl die Gesamtstruktur als auch die funktionalen Kernkomponenten vorgestellt.
Dabei wurde besonders auf das Kernsystem eingegangen,
und außerdem die zwei Erweiterungen umrandet.

Um die Eigenschaften und die Möglichkeiten dieses Systems praktisch zu ergründen, ist es notwendig, das Kernsystem vollständig zu implementieren.
Um die Erweiterbarkeit zu untersuchen, ist zumindest eine der beiden Beispiel-Erweiterungen umzusetzen. Dabei ist die Umsetzung,
der Datenanalyse erfolgversprechender, da hier die initiale Analyse bereits mehrere Arbeitspakete umfasst, während die Analyse der Testresultate dies in der Benutzeroberfläche umsetzen müsste (und die Benutzeroberfläche wird in dieser Arbeit nicht behandelt).
